{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.042621Z",
     "start_time": "2025-11-02T15:18:19.994522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"features.csv\")\n",
    "data = data[[\"url\", \"label\"]]\n",
    "data.head()"
   ],
   "id": "9b321e08fae6effa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            url  label\n",
       "0  http://4aoo-bmmanager045288.vercel.app/?naps      0\n",
       "1  http://0suz-bmmanager047181.vercel.app/?naps      0\n",
       "2     http://ncrm-casefb588197.vercel.app/?naps      0\n",
       "3     http://casefb668303-f2w6.vercel.app/?naps      0\n",
       "4     http://casefb480777-qhn9.vercel.app/?naps      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://4aoo-bmmanager045288.vercel.app/?naps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://0suz-bmmanager047181.vercel.app/?naps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://ncrm-casefb588197.vercel.app/?naps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://casefb668303-f2w6.vercel.app/?naps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://casefb480777-qhn9.vercel.app/?naps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.076316Z",
     "start_time": "2025-11-02T15:18:20.069527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# (A) Reproduzierbarkeit (optional)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ],
   "id": "4d4e8f1e2cf1416",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CNN",
   "id": "b6c9a0fd454dda62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.115154Z",
     "start_time": "2025-11-02T15:18:20.102565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# (B) Train/Val/Test-Split\n",
    "X_train_df, X_test_df = train_test_split(data, test_size=0.2, stratify=data[\"label\"], random_state=SEED)\n",
    "X_train_df, X_val_df  = train_test_split(X_train_df, test_size=0.2, stratify=X_train_df[\"label\"], random_state=SEED)\n",
    "\n",
    "y_train = X_train_df[\"label\"].astype(\"int32\").to_numpy()\n",
    "y_val   = X_val_df[\"label\"].astype(\"int32\").to_numpy()\n",
    "y_test  = X_test_df[\"label\"].astype(\"int32\").to_numpy()\n",
    "\n",
    "X_train_str = X_train_df[\"url\"].astype(str).to_numpy()\n",
    "X_val_str   = X_val_df[\"url\"].astype(str).to_numpy()\n",
    "X_test_str  = X_test_df[\"url\"].astype(str).to_numpy()"
   ],
   "id": "7ad0382ac4a061e1",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T16:16:05.318214Z",
     "start_time": "2025-11-02T16:16:05.301868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (C) Sequenzlänge auf Trainingsdaten festlegen (z. B. 95. Perzentil, min 8)\n",
    "train_lengths = np.array([len(u) for u in X_train_str], dtype=np.int32)\n",
    "MAX_LEN = max(8, int(np.percentile(train_lengths, 95)))\n",
    "\n",
    "print(train_lengths)\n",
    "print(MAX_LEN)"
   ],
   "id": "aacd3668929d50c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33 52 94 ... 47 26 97]\n",
      "107\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.169187Z",
     "start_time": "2025-11-02T15:18:20.150065Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # (D) StringLookup-Vokabular nur auf TRAIN adaptieren:\n",
    "#     - unicode_split: URLs -> Zeichen\n",
    "#     - Ragged -> Batchweise\n",
    "train_text_ds = tf.data.Dataset.from_tensor_slices(X_train_str).batch(1024)\n",
    "char_ds = train_text_ds.map(lambda batch: tf.strings.unicode_split(batch, \"UTF-8\"))  # Ragged[str] pro Batch"
   ],
   "id": "56c4f9daf757fb01",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.213931Z",
     "start_time": "2025-11-02T15:18:20.181508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import layers\n",
    "\n",
    "# StringLookup:\n",
    "# - mask_token=\"\"  -> Index 0 wird für Padding reserviert (Embedding mask_zero=True)\n",
    "# - oov_token=\"[UNK]\" -> Unbekannte Zeichen landen in OOV-Bucket\n",
    "lookup = layers.StringLookup(\n",
    "    mask_token=\"\",\n",
    "    oov_token=\"[UNK]\",\n",
    "    num_oov_indices=1,\n",
    "    output_mode=\"int\",\n",
    "    name=\"char_lookup\",\n",
    ")\n",
    "lookup.adapt(char_ds)  # Nur Trainingsdaten!\n",
    "VOCAB_SIZE = lookup.vocabulary_size()  # inkl. PAD(0) + OOV\n",
    "VOCAB_SIZE"
   ],
   "id": "250deb2bc66fe8ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.230785Z",
     "start_time": "2025-11-02T15:18:20.226129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =======================================================\n",
    "# MODELLDEFINITION (mit Vorverarbeitung im Graph)\n",
    "# =======================================================\n",
    "# Eingabe: roher URL-String\n",
    "inp = layers.Input(shape=(), dtype=tf.string, name=\"input_url_str\")\n",
    "\n",
    "# 1) Unicode in Zeichen splitten (als Keras-Layer, damit kein KerasTensor-Fehler entsteht)\n",
    "chars = layers.Lambda(lambda x: tf.strings.unicode_split(x, \"UTF-8\"),\n",
    "                      name=\"unicode_split\", output_shape=(None,))(inp)  # -> RaggedTensor[str]\n",
    "\n",
    "# 2) Zeichen -> Indizes (PAD wird intern Index 0 sein, OOV > 0)\n",
    "idx_rt = lookup(chars)  # lookup ist ein StringLookup-Layer, zuvor auf TRAIN adaptiert\n",
    "\n",
    "# 3) Ragged[int] -> Dense[int] mit fester Länge und PAD=0\n",
    "#    WICHTIG: default_value muss gleichen dtype wie idx_rt haben!\n",
    "idx = layers.Lambda(\n",
    "    lambda rt: rt.to_tensor(\n",
    "        default_value=tf.cast(0, rt.dtype),              # sichert gleichen dtype\n",
    "        shape=[tf.shape(rt)[0], MAX_LEN]                 # (B, MAX_LEN)\n",
    "    ),\n",
    "    name=\"pad_to_max_len\",\n",
    "    output_shape=(MAX_LEN,)  # pro Sample: feste Länge MAX_LEN\n",
    ")(idx_rt)"
   ],
   "id": "396dafbeb8d0ce4a",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.248696Z",
     "start_time": "2025-11-02T15:18:20.242743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# Embedding (mask_zero=True -> Index 0 wird als PAD maskiert)\n",
    "# -----------------------------------------------------------\n",
    "# >>> Embedding <<<\n",
    "x = layers.Embedding(\n",
    "    input_dim=VOCAB_SIZE,   # wird aus lookup.vocabulary_size() übernommen\n",
    "    output_dim=64,          # gewünschte Embedding-Dimension\n",
    "    name=\"embedding\"\n",
    ")(idx)\n"
   ],
   "id": "4a04dc5651a35238",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.263230Z",
     "start_time": "2025-11-02T15:18:20.259912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------\n",
    "# Dropout\n",
    "# ---------\n",
    "x = layers.Dropout(rate=0.2, name=\"Dropout\")(x)"
   ],
   "id": "a8152cec137f9dc2",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.283160Z",
     "start_time": "2025-11-02T15:18:20.274560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PAD-Positionen explizit auf 0 nullen (Feature-Vektoren dort = 0)\n",
    "pad_mask = layers.Lambda(\n",
    "    lambda t: tf.cast(tf.not_equal(t, 0), x.dtype),  # (B, T), 1 = echt, 0 = PAD\n",
    "    name=\"pad_mask\"\n",
    ")(idx)\n",
    "pad_mask = layers.Lambda(lambda m: tf.expand_dims(m, -1), name=\"pad_mask_expand\")(pad_mask)  # (B, T, 1)\n",
    "x = layers.Multiply(name=\"apply_pad_mask\")([x, pad_mask])  # (B, T, 64), PAD exakt 0\n",
    "\n",
    "\n",
    "# -------\n",
    "# Conv1D\n",
    "# -------\n",
    "x = layers.Conv1D(\n",
    "    filters=64,\n",
    "    kernel_size=5,\n",
    "    activation=\"relu\",\n",
    "    use_bias=False,\n",
    "    name=\"Conv1D\"\n",
    ")(x)"
   ],
   "id": "54338137931cfed3",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.296461Z",
     "start_time": "2025-11-02T15:18:20.294233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------\n",
    "# MaxPooling1D\n",
    "# --------------\n",
    "x = layers.MaxPooling1D(pool_size=4, name=\"MaxPooling1D\")(x)\n"
   ],
   "id": "e970732e97537626",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.309958Z",
     "start_time": "2025-11-02T15:18:20.307866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------\n",
    "# GlobalMaxPooling1D\n",
    "# ----------------------\n",
    "x = layers.GlobalMaxPooling1D(name=\"GlobalMaxPooling1D\")(x)\n"
   ],
   "id": "22d2a2fa2a011503",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.338229Z",
     "start_time": "2025-11-02T15:18:20.332450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----\n",
    "# Dense\n",
    "# -----\n",
    "# (zweiklassige Ausgabe, softmax)\n",
    "out = layers.Dense(units=2, activation=\"softmax\", name=\"Dense_Output\")(x)\n"
   ],
   "id": "63acc04888278775",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.350674Z",
     "start_time": "2025-11-02T15:18:20.347880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import models\n",
    "\n",
    "# -------------------------\n",
    "# Modell zusammenbauen\n",
    "# -------------------------\n",
    "model = models.Model(inp, out, name=\"cnn_phishing_urls_charlevel\")\n"
   ],
   "id": "646b6ab507e1e326",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.366442Z",
     "start_time": "2025-11-02T15:18:20.361913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------\n",
    "# Kompilieren\n",
    "# -------------------------\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ],
   "id": "4ebfe80f00b45583",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:20.379199Z",
     "start_time": "2025-11-02T15:18:20.377380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import callbacks\n",
    "\n",
    "#-------------------------\n",
    "# Early Stopping\n",
    "# -------------------------\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1\n",
    ")"
   ],
   "id": "4a7c14530a8acb08",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:43.424256Z",
     "start_time": "2025-11-02T15:18:20.390534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------\n",
    "# Training\n",
    "# -------------------------\n",
    "history = model.fit(\n",
    "    X_train_str,\n",
    "    y_train,\n",
    "    validation_data=(X_val_str, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")"
   ],
   "id": "24122bf040ac24c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.6571 - loss: 0.5968 - val_accuracy: 0.8358 - val_loss: 0.3804\n",
      "Epoch 2/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8530 - loss: 0.3487 - val_accuracy: 0.8899 - val_loss: 0.2865\n",
      "Epoch 3/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8869 - loss: 0.2718 - val_accuracy: 0.9086 - val_loss: 0.2462\n",
      "Epoch 4/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9095 - loss: 0.2287 - val_accuracy: 0.9150 - val_loss: 0.2258\n",
      "Epoch 5/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9222 - loss: 0.2030 - val_accuracy: 0.9182 - val_loss: 0.2140\n",
      "Epoch 6/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9297 - loss: 0.1854 - val_accuracy: 0.9234 - val_loss: 0.2049\n",
      "Epoch 7/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9389 - loss: 0.1670 - val_accuracy: 0.9269 - val_loss: 0.1976\n",
      "Epoch 8/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9411 - loss: 0.1578 - val_accuracy: 0.9281 - val_loss: 0.1913\n",
      "Epoch 9/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9467 - loss: 0.1441 - val_accuracy: 0.9281 - val_loss: 0.1894\n",
      "Epoch 10/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9507 - loss: 0.1345 - val_accuracy: 0.9330 - val_loss: 0.1854\n",
      "Epoch 11/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9526 - loss: 0.1281 - val_accuracy: 0.9330 - val_loss: 0.1832\n",
      "Epoch 12/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9578 - loss: 0.1178 - val_accuracy: 0.9351 - val_loss: 0.1811\n",
      "Epoch 13/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9600 - loss: 0.1130 - val_accuracy: 0.9339 - val_loss: 0.1785\n",
      "Epoch 14/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9624 - loss: 0.1061 - val_accuracy: 0.9354 - val_loss: 0.1783\n",
      "Epoch 15/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9615 - loss: 0.1044 - val_accuracy: 0.9365 - val_loss: 0.1760\n",
      "Epoch 16/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9643 - loss: 0.0972 - val_accuracy: 0.9371 - val_loss: 0.1766\n",
      "Epoch 17/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9671 - loss: 0.0920 - val_accuracy: 0.9374 - val_loss: 0.1719\n",
      "Epoch 18/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9703 - loss: 0.0879 - val_accuracy: 0.9377 - val_loss: 0.1741\n",
      "Epoch 19/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9732 - loss: 0.0830 - val_accuracy: 0.9397 - val_loss: 0.1715\n",
      "Epoch 20/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9730 - loss: 0.0791 - val_accuracy: 0.9397 - val_loss: 0.1737\n",
      "Epoch 21/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9754 - loss: 0.0750 - val_accuracy: 0.9421 - val_loss: 0.1744\n",
      "Epoch 22/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9768 - loss: 0.0728 - val_accuracy: 0.9429 - val_loss: 0.1739\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.171149Z",
     "start_time": "2025-11-02T15:18:43.824415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -------------------------\n",
    "# Testen / Evaluieren\n",
    "# -------------------------\n",
    "test_loss, test_acc = model.evaluate(X_test_str, y_test, verbose=0)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Klassifikationsbericht & Konfusionsmatrix\n",
    "y_proba = model.predict(X_test_str, batch_size=512, verbose=0)\n",
    "y_pred  = np.argmax(y_proba, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4, target_names=[\"Phishing(0)\", \"Legit(1)\"]))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "9f5be9ac0d231553",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.1766 | Test Accuracy: 0.9338\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Phishing(0)     0.9370    0.8804    0.9079      1589\n",
      "    Legit(1)     0.9321    0.9652    0.9484      2704\n",
      "\n",
      "    accuracy                         0.9338      4293\n",
      "   macro avg     0.9346    0.9228    0.9281      4293\n",
      "weighted avg     0.9340    0.9338    0.9334      4293\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1399  190]\n",
      " [  94 2610]]\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.214552Z",
     "start_time": "2025-11-02T15:18:44.183770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "CLASS_NAMES = [\"Phishing (0)\", \"Legitim (1)\"]\n",
    "\n",
    "def predict_urls_batch(model, urls: list[str]) -> pd.DataFrame:\n",
    "    x = np.array(urls, dtype=object)\n",
    "    proba = model.predict(x, verbose=0)  # shape: (N, 2)\n",
    "    pred_idx = proba.argmax(axis=1)\n",
    "    df = pd.DataFrame({\n",
    "        \"url\": urls,\n",
    "        \"pred_index\": pred_idx,\n",
    "        \"pred_label\": [CLASS_NAMES[i] for i in pred_idx],\n",
    "        \"proba_phishing\": proba[:, 0],\n",
    "        \"proba_legitim\":  proba[:, 1],\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# Beispiel:\n",
    "urls = [\"https://www.google.de/\", \"http://suspicious.example/offer?=free\", \"http://yield.beefyhubs.lol\", \"https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup\"]\n",
    "print(predict_urls_batch(model, urls))"
   ],
   "id": "93f87d7075dfd416",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 url  pred_index  \\\n",
      "0                             https://www.google.de/           1   \n",
      "1              http://suspicious.example/offer?=free           1   \n",
      "2                         http://yield.beefyhubs.lol           0   \n",
      "3  https://www.tensorflow.org/api_docs/python/tf/...           1   \n",
      "\n",
      "     pred_label  proba_phishing  proba_legitim  \n",
      "0   Legitim (1)        0.063284       0.936716  \n",
      "1   Legitim (1)        0.441414       0.558586  \n",
      "2  Phishing (0)        0.906884       0.093116  \n",
      "3   Legitim (1)        0.001245       0.998755  \n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LSTM",
   "id": "6ed6f9d5299adfee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.241899Z",
     "start_time": "2025-11-02T15:18:44.238088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# >>> Embedding <<<\n",
    "x = layers.Embedding(\n",
    "    input_dim=VOCAB_SIZE,   # wird aus lookup.vocabulary_size() übernommen\n",
    "    output_dim=64,          # gewünschte Embedding-Dimension\n",
    "    name=\"embedding\"\n",
    ")(idx)"
   ],
   "id": "855456dddf5bf6c8",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.258387Z",
     "start_time": "2025-11-02T15:18:44.252035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Explizit: PAD-Vektoren auf 0 setzen (sicher stellt, dass PADDING nichts beiträgt)\n",
    "pad_mask_float = layers.Lambda(lambda t: tf.cast(tf.not_equal(t, 0), x.dtype), name=\"pad_mask_float\")(idx)  # (B, T)\n",
    "x = layers.Multiply(name=\"apply_pad_mask\")([x, layers.Lambda(lambda m: tf.expand_dims(m, -1))(pad_mask_float)])  # (B, T, 64)\n"
   ],
   "id": "ae40107ce429532d",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.273791Z",
     "start_time": "2025-11-02T15:18:44.270683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dropout\n",
    "x = layers.Dropout(0.2, name=\"dropout\")(x)"
   ],
   "id": "322183c6dcf8c5b7",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.289571Z",
     "start_time": "2025-11-02T15:18:44.285543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Conv1D ohne Bias (Nullfenster erzeugen keine Aktivierung)\n",
    "x = layers.Conv1D(filters=64, kernel_size=5, activation=\"relu\", use_bias=False, name=\"conv1d\")(x)"
   ],
   "id": "5ba6962717535e30",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.304330Z",
     "start_time": "2025-11-02T15:18:44.301860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MaxPooling1D\n",
    "x = layers.MaxPooling1D(pool_size=4, name=\"maxpool\")(x)  # (B, T', 64)"
   ],
   "id": "d9b292c128d41fa4",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.322132Z",
     "start_time": "2025-11-02T15:18:44.315789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# >>> Maske für LSTM passend zum gepoolten Zeitmaß berechnen <<<\n",
    "# Ursprungsmaske (B, T, 1)\n",
    "mask_expanded = layers.Lambda(lambda m: tf.expand_dims(m, -1), name=\"mask_expand\")(pad_mask_float)  # (B, T, 1)\n",
    "# Mit derselben Pooling-Config auf die Maske anwenden (ANY in Fenster -> True)\n",
    "mask_pooled = layers.MaxPooling1D(pool_size=4, name=\"mask_pool\")(mask_expanded)  # (B, T', 1)\n",
    "mask_lstm = layers.Lambda(lambda m: tf.squeeze(tf.cast(m > 0, tf.bool), axis=-1), name=\"mask_bool\")(mask_pooled)  # (B, T')"
   ],
   "id": "fbb6d86addca5682",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.343825Z",
     "start_time": "2025-11-02T15:18:44.334065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# >>> LSTM statt GlobalMaxPooling1D <<<\n",
    "x = layers.LSTM(64, name=\"lstm\")(x, mask=mask_lstm)  # (B, 64)"
   ],
   "id": "c7a0f7f3ec7ec7b2",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.360879Z",
     "start_time": "2025-11-02T15:18:44.356203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Output\n",
    "out = layers.Dense(2, activation=\"softmax\", name=\"output\")(x)"
   ],
   "id": "162705e6c8bd01a6",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.375512Z",
     "start_time": "2025-11-02T15:18:44.372471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import models\n",
    "\n",
    "# -------------------------\n",
    "# Modell zusammenbauen\n",
    "# -------------------------\n",
    "model = models.Model(inp, out, name=\"lstm_phishing_urls_charlevel\")\n"
   ],
   "id": "d9e1e6df96bdf471",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.390629Z",
     "start_time": "2025-11-02T15:18:44.386747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------\n",
    "# Kompilieren\n",
    "# -------------------------\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ],
   "id": "a40311e4c0a0e2f",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:18:44.403715Z",
     "start_time": "2025-11-02T15:18:44.401794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import callbacks\n",
    "\n",
    "#-------------------------\n",
    "# Early Stopping\n",
    "# -------------------------\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1\n",
    ")"
   ],
   "id": "6ab527331086ba81",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:19:21.603759Z",
     "start_time": "2025-11-02T15:18:44.426215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------\n",
    "# Training\n",
    "# -------------------------\n",
    "history = model.fit(\n",
    "    X_train_str,\n",
    "    y_train,\n",
    "    validation_data=(X_val_str, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")"
   ],
   "id": "93f67e85321666da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step - accuracy: 0.6766 - loss: 0.5739 - val_accuracy: 0.8328 - val_loss: 0.3744\n",
      "Epoch 2/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.8673 - loss: 0.2973 - val_accuracy: 0.8928 - val_loss: 0.2585\n",
      "Epoch 3/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.9045 - loss: 0.2237 - val_accuracy: 0.9089 - val_loss: 0.2255\n",
      "Epoch 4/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 25ms/step - accuracy: 0.9195 - loss: 0.1867 - val_accuracy: 0.9115 - val_loss: 0.2310\n",
      "Epoch 5/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.9240 - loss: 0.1808 - val_accuracy: 0.9185 - val_loss: 0.2030\n",
      "Epoch 6/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.9353 - loss: 0.1579 - val_accuracy: 0.9249 - val_loss: 0.1945\n",
      "Epoch 7/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.9369 - loss: 0.1490 - val_accuracy: 0.9278 - val_loss: 0.2033\n",
      "Epoch 8/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.9398 - loss: 0.1448 - val_accuracy: 0.9289 - val_loss: 0.1918\n",
      "Epoch 9/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.9437 - loss: 0.1355 - val_accuracy: 0.9255 - val_loss: 0.1745\n",
      "Epoch 10/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.9479 - loss: 0.1256 - val_accuracy: 0.9249 - val_loss: 0.1713\n",
      "Epoch 11/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.9558 - loss: 0.1174 - val_accuracy: 0.9292 - val_loss: 0.1618\n",
      "Epoch 12/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.9604 - loss: 0.1040 - val_accuracy: 0.9275 - val_loss: 0.1661\n",
      "Epoch 13/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.9617 - loss: 0.0985 - val_accuracy: 0.9269 - val_loss: 0.1706\n",
      "Epoch 14/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - accuracy: 0.9622 - loss: 0.0995 - val_accuracy: 0.9109 - val_loss: 0.2101\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:19:22.454891Z",
     "start_time": "2025-11-02T15:19:21.727276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -------------------------\n",
    "# Testen / Evaluieren\n",
    "# -------------------------\n",
    "test_loss, test_acc = model.evaluate(X_test_str, y_test, verbose=0)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Klassifikationsbericht & Konfusionsmatrix\n",
    "y_proba = model.predict(X_test_str, batch_size=512, verbose=0)\n",
    "y_pred  = np.argmax(y_proba, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4, target_names=[\"Phishing(0)\", \"Legit(1)\"]))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "3a40321334c27378",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.1663 | Test Accuracy: 0.9359\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Phishing(0)     0.9334    0.8905    0.9114      1589\n",
      "    Legit(1)     0.9373    0.9626    0.9498      2704\n",
      "\n",
      "    accuracy                         0.9359      4293\n",
      "   macro avg     0.9354    0.9266    0.9306      4293\n",
      "weighted avg     0.9359    0.9359    0.9356      4293\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1415  174]\n",
      " [ 101 2603]]\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:19:22.497940Z",
     "start_time": "2025-11-02T15:19:22.467299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "CLASS_NAMES = [\"Phishing (0)\", \"Legitim (1)\"]\n",
    "\n",
    "def predict_urls_batch(model, urls: list[str]) -> pd.DataFrame:\n",
    "    x = np.array(urls, dtype=object)\n",
    "    proba = model.predict(x, verbose=0)  # shape: (N, 2)\n",
    "    pred_idx = proba.argmax(axis=1)\n",
    "    df = pd.DataFrame({\n",
    "        \"url\": urls,\n",
    "        \"pred_index\": pred_idx,\n",
    "        \"pred_label\": [CLASS_NAMES[i] for i in pred_idx],\n",
    "        \"proba_phishing\": proba[:, 0],\n",
    "        \"proba_legitim\":  proba[:, 1],\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# Beispiel:\n",
    "urls = [\"https://www.google.de/\", \"http://suspicious.example/offer?=free\", \"http://yield.beefyhubs.lol\", \"https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup\"]\n",
    "print(predict_urls_batch(model, urls))"
   ],
   "id": "4cccaf0f920389ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 url  pred_index  \\\n",
      "0                             https://www.google.de/           1   \n",
      "1              http://suspicious.example/offer?=free           1   \n",
      "2                         http://yield.beefyhubs.lol           0   \n",
      "3  https://www.tensorflow.org/api_docs/python/tf/...           1   \n",
      "\n",
      "     pred_label  proba_phishing  proba_legitim  \n",
      "0   Legitim (1)        0.064909       0.935091  \n",
      "1   Legitim (1)        0.277159       0.722841  \n",
      "2  Phishing (0)        0.915081       0.084919  \n",
      "3   Legitim (1)        0.001309       0.998691  \n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### BILSTM/CNN",
   "id": "d483ec6f52ef09d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:59:26.874435Z",
     "start_time": "2025-11-02T15:59:26.868949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "\n",
    "# Eingabe: roher URL-String\n",
    "inp = layers.Input(shape=(), dtype=tf.string, name=\"input_url_str\")\n",
    "\n",
    "# Unicode -> Zeichen (Ragged[str]); output_shape nötig, damit Keras die Form kennt\n",
    "chars = layers.Lambda(\n",
    "    lambda x: tf.strings.unicode_split(x, \"UTF-8\"),\n",
    "    name=\"unicode_split\",\n",
    "    output_shape=(None,)\n",
    ")(inp)\n",
    "\n",
    "# Ragged[str] -> Dense[str] (Padding mit \"\" für mask_token=\"\")\n",
    "padded_chars = layers.Lambda(\n",
    "    lambda rt: rt.to_tensor(default_value=\"\", shape=[tf.shape(rt)[0], MAX_LEN]),\n",
    "    name=\"pad_to_max_len_str\",\n",
    "    output_shape=(MAX_LEN,)\n",
    ")(chars)\n",
    "\n",
    "# StringLookup -> Indizes (PAD=0 dank mask_token=\"\")\n",
    "idx = lookup(padded_chars)  # Tensor[int32] Form: (B, MAX_LEN)\n"
   ],
   "id": "801e6b96c62e122f",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:59:29.887262Z",
     "start_time": "2025-11-02T15:59:29.854008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embedding mit Maskierung (LSTM versteht Masken)\n",
    "x = layers.Embedding(\n",
    "    input_dim=lookup.vocabulary_size(),\n",
    "    output_dim=64,\n",
    "    mask_zero=True,\n",
    "    name=\"embedding\"\n",
    ")(idx)\n",
    "\n",
    "# Bidirektionale LSTM mit Sequenzausgabe\n",
    "x = layers.Bidirectional(\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    name=\"bilstm\"\n",
    ")(x)\n",
    "\n",
    "# Sicherstellen, dass PAD-Zeitschritte wirklich 0 sind (optional, aber sauber für Conv)\n",
    "pad_bool = layers.Lambda(lambda t: tf.not_equal(t, 0), name=\"pad_bool\")(idx)      # (B, T)\n",
    "pad_float = layers.Lambda(lambda b: tf.cast(b, x.dtype), name=\"pad_float\")(pad_bool)\n",
    "pad_float = layers.Lambda(lambda m: tf.expand_dims(m, -1), name=\"pad_expand\")(pad_float)  # (B, T, 1)\n",
    "x = layers.Multiply(name=\"apply_pad_after_lstm\")([x, pad_float])\n",
    "\n",
    "# CNN-Block (lokale Muster auf kontextualisierten Hiddens) – ohne Bias, damit 0-Fenster neutral sind\n",
    "x = layers.Dropout(0.2, name=\"dropout\")(x)\n",
    "x = layers.Conv1D(64, 5, activation=\"relu\", use_bias=False, name=\"conv1d\")(x)\n",
    "x = layers.MaxPooling1D(pool_size=4, name=\"maxpool\")(x)\n",
    "\n",
    "# Zusammenfassen der Zeitachse\n",
    "x = layers.GlobalMaxPooling1D(name=\"global_maxpool\")(x)\n",
    "\n",
    "# Output\n",
    "out = layers.Dense(2, activation=\"softmax\", name=\"output\")(x)\n",
    "\n",
    "model_bilstm_cnn = models.Model(inp, out, name=\"hybrid_bilstm_cnn\")\n"
   ],
   "id": "d994bffed6a2d2c4",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:59:31.837145Z",
     "start_time": "2025-11-02T15:59:31.830097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------\n",
    "# Kompilieren\n",
    "# -------------------------\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ],
   "id": "e3090c4b82713953",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:59:34.550742Z",
     "start_time": "2025-11-02T15:59:34.547493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import callbacks\n",
    "\n",
    "#-------------------------\n",
    "# Early Stopping\n",
    "# -------------------------\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1\n",
    ")"
   ],
   "id": "92dd7c1da2f96d19",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:59:47.330479Z",
     "start_time": "2025-11-02T15:59:36.228492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------\n",
    "# Training\n",
    "# -------------------------\n",
    "history = model.fit(\n",
    "    X_train_str,\n",
    "    y_train,\n",
    "    validation_data=(X_val_str, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")"
   ],
   "id": "efaf5cbb7ea41485",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.9586 - loss: 0.1063 - val_accuracy: 0.9336 - val_loss: 0.1643\n",
      "Epoch 2/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.9725 - loss: 0.0736 - val_accuracy: 0.9298 - val_loss: 0.1744\n",
      "Epoch 3/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.9755 - loss: 0.0666 - val_accuracy: 0.9324 - val_loss: 0.1699\n",
      "Epoch 4/30\n",
      "\u001B[1m108/108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - accuracy: 0.9743 - loss: 0.0681 - val_accuracy: 0.9359 - val_loss: 0.1764\n",
      "Epoch 4: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T16:00:01.958700Z",
     "start_time": "2025-11-02T16:00:01.242554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -------------------------\n",
    "# Testen / Evaluieren\n",
    "# -------------------------\n",
    "test_loss, test_acc = model.evaluate(X_test_str, y_test, verbose=0)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Klassifikationsbericht & Konfusionsmatrix\n",
    "y_proba = model.predict(X_test_str, batch_size=512, verbose=0)\n",
    "y_pred  = np.argmax(y_proba, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4, target_names=[\"Phishing(0)\", \"Legit(1)\"]))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "c0486460f6a3a9f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.1762 | Test Accuracy: 0.9352\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Phishing(0)     0.9426    0.8785    0.9094      1589\n",
      "    Legit(1)     0.9314    0.9686    0.9496      2704\n",
      "\n",
      "    accuracy                         0.9352      4293\n",
      "   macro avg     0.9370    0.9236    0.9295      4293\n",
      "weighted avg     0.9355    0.9352    0.9347      4293\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1396  193]\n",
      " [  85 2619]]\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T16:00:04.863485Z",
     "start_time": "2025-11-02T16:00:04.824564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "CLASS_NAMES = [\"Phishing (0)\", \"Legitim (1)\"]\n",
    "\n",
    "def predict_urls_batch(model, urls: list[str]) -> pd.DataFrame:\n",
    "    x = np.array(urls, dtype=object)\n",
    "    proba = model.predict(x, verbose=0)  # shape: (N, 2)\n",
    "    pred_idx = proba.argmax(axis=1)\n",
    "    df = pd.DataFrame({\n",
    "        \"url\": urls,\n",
    "        \"pred_index\": pred_idx,\n",
    "        \"pred_label\": [CLASS_NAMES[i] for i in pred_idx],\n",
    "        \"proba_phishing\": proba[:, 0],\n",
    "        \"proba_legitim\":  proba[:, 1],\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# Beispiel:\n",
    "urls = [\"https://www.google.de/\", \"http://suspicious.example/offer?=free\", \"http://yield.beefyhubs.lol\", \"https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup\"]\n",
    "print(predict_urls_batch(model, urls))"
   ],
   "id": "b9933f8caf2a4688",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 url  pred_index  \\\n",
      "0                             https://www.google.de/           1   \n",
      "1              http://suspicious.example/offer?=free           1   \n",
      "2                         http://yield.beefyhubs.lol           0   \n",
      "3  https://www.tensorflow.org/api_docs/python/tf/...           1   \n",
      "\n",
      "     pred_label  proba_phishing  proba_legitim  \n",
      "0   Legitim (1)        0.014444       0.985556  \n",
      "1   Legitim (1)        0.251571       0.748429  \n",
      "2  Phishing (0)        0.769697       0.230303  \n",
      "3   Legitim (1)        0.000565       0.999435  \n"
     ]
    }
   ],
   "execution_count": 104
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
